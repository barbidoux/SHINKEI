============================= test session starts ==============================
platform linux -- Python 3.12.3, pytest-8.4.2, pluggy-1.6.0 -- /home/barbidou/.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/bin/python
cachedir: .pytest_cache
rootdir: /home/barbidou/SHINKEI/backend
configfile: pyproject.toml
plugins: cov-6.3.0, anyio-4.11.0, asyncio-0.24.0, mock-3.15.1
asyncio: mode=Mode.AUTO, default_loop_scope=session
collecting ... collected 3 items

tests/api/test_users.py::test_create_user ERROR                          [ 33%]
tests/api/test_users.py::test_read_user_me ERROR                         [ 66%]
tests/api/test_users.py::test_update_user_me ERROR                       [100%]

==================================== ERRORS ====================================
______________________ ERROR at setup of test_create_user ______________________

request = <SubRequest 'engine' for <Coroutine test_create_user>>, kwargs = {}
func = <function engine at 0x7fe1b3bc2ca0>
event_loop_fixture_id = '_session_event_loop'
setup = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup at 0x7fe1b1615940>
finalizer = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.finalizer at 0x7fe1b16158a0>

    @functools.wraps(fixture)
    def _asyncgen_fixture_wrapper(request: FixtureRequest, **kwargs: Any):
        func = _perhaps_rebind_fixture_func(fixture, request.instance)
        event_loop_fixture_id = _get_event_loop_fixture_id_for_async_fixture(
            request, func
        )
        event_loop = request.getfixturevalue(event_loop_fixture_id)
        kwargs.pop(event_loop_fixture_id, None)
        gen_obj = func(**_add_kwargs(func, kwargs, event_loop, request))
    
        async def setup():
            res = await gen_obj.__anext__()  # type: ignore[union-attr]
            return res
    
        def finalizer() -> None:
            """Yield again, to finalize."""
    
            async def async_finalizer() -> None:
                try:
                    await gen_obj.__anext__()  # type: ignore[union-attr]
                except StopAsyncIteration:
                    pass
                else:
                    msg = "Async generator fixture didn't stop."
                    msg += "Yield only once."
                    raise ValueError(msg)
    
            event_loop.run_until_complete(async_finalizer())
    
>       result = event_loop.run_until_complete(setup())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:343: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup() done, defined at /home/barbidou/.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:324> exception=ConnectionRefusedError(111, "Connect call failed ('127.0.0.1', 5432)")>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def setup():
>       res = await gen_obj.__anext__()  # type: ignore[union-attr]
              ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @pytest.fixture(scope="session")
    async def engine() -> AsyncGenerator:
        """Create a SQLAlchemy engine for testing."""
        engine = create_async_engine(TEST_DATABASE_URL, echo=False)
    
        # Create tables
>       async with engine.begin() as conn:

tests/conftest.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._AsyncGeneratorContextManager object at 0x7fe1b15d5820>

    async def __aenter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
>           return await anext(self.gen)
                   ^^^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/contextlib.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncEngine object at 0x7fe1b1724c10>

    @contextlib.asynccontextmanager
    async def begin(self) -> AsyncIterator[AsyncConnection]:
        """Return a context manager which when entered will deliver an
        :class:`_asyncio.AsyncConnection` with an
        :class:`_asyncio.AsyncTransaction` established.
    
        E.g.::
    
            async with async_engine.begin() as conn:
                await conn.execute(
                    text("insert into table (x, y, z) values (1, 2, 3)")
                )
                await conn.execute(text("my_special_procedure(5)"))
    
        """
        conn = self.connect()
    
>       async with conn:

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:1068: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/base.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
>               result = context.throw(*sys.exc_info())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7fe1b15d57c0>
engine = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()
                                         ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()
               ^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:447: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()
                  ^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:711: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b28fadd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()
                       ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)
               ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:388: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:673: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:899: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b170ffd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:895: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/create.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7fe1b15d5be0>
cargs = ()
cparams = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}

    def connect(self, *cargs: Any, **cparams: Any) -> DBAPIConnection:
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:629: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x7fe1b2519df0>
arg = ()
kw = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x7fe1b2baac00>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:955: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object connect at 0x7fe1b24365c0>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
>               value = await result
                        ^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=None,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None,
                      krbsrvname=None,
                      gsslib=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote_plus`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :param str krbsrvname:
            Kerberos service name to use when authenticating with GSSAPI. This
            must match the server configuration. Defaults to 'postgres'.
    
        :param str gsslib:
            GSS library to use for GSSAPI/SSPI authentication. Can be 'gssapi'
            or 'sspi'. Defaults to 'sspi' on Windows and 'gssapi' otherwise.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.run(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. versionchanged:: 0.30.0
           Added the *krbsrvname* and *gsslib* parameters.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs,
                krbsrvname=krbsrvname,
                gsslib=gsslib,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connection.py:2421: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
                conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )
                candidates.append(conn)
                if await _can_use_connection(conn, target_attr):
                    chosen_connection = conn
                    break
            except OSError as ex:
                last_error = ex
        else:
            if target_attr == SessionAttribute.prefer_standby and candidates:
                chosen_connection = random.choice(candidates)
    
        await asyncio.gather(
            *(c.close() for c in candidates if c is not chosen_connection),
            return_exceptions=True
        )
    
        if chosen_connection:
            return chosen_connection
    
>       raise last_error or exceptions.TargetServerAttributeNotMatched(
            'None of the hosts match the target attribute requirement '
            '{!r}'.format(target_attr)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1075: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1049: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:886: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
retry = True, addr = ('localhost', 5432)
loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.ssl_negotiation is SSLNegotiation.direct:
            # if ssl and ssl_negotiation is `direct`, skip STARTTLS and perform
            # direct SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
>       tr, pr = await connector
                 ^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:931: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

protocol_factory = <function __connect_addr.<locals>.<lambda> at 0x7fe1b1616840>
host = 'localhost', port = 5432

    async def _create_ssl_connection(protocol_factory, host, port, *,
                                     loop, ssl_context, ssl_is_advisory=False):
    
>       tr, pr = await loop.create_connection(
            lambda: TLSUpgradeProto(loop, host, port,
                                    ssl_context, ssl_is_advisory),
            host, port)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
                        sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)
                        break
                    except OSError:
                        continue
            else:  # using happy eyeballs
                sock, _, _ = await staggered.staggered_race(
                    (functools.partial(self._connect_sock,
                                       exceptions, addrinfo, laddr_infos)
                     for addrinfo in infos),
                    happy_eyeballs_delay, loop=self)
    
            if sock is None:
                exceptions = [exc for sub in exceptions for exc in sub]
                try:
                    if all_errors:
                        raise ExceptionGroup("create_connection failed", exceptions)
                    if len(exceptions) == 1:
>                       raise exceptions[0]

/usr/lib/python3.12/asyncio/base_events.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
>                       sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)

/usr/lib/python3.12/asyncio/base_events.py:1104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
exceptions = None
addr_info = (<AddressFamily.AF_INET: 2>, <SocketKind.SOCK_STREAM: 1>, 6, '', ('127.0.0.1', 5432))
local_addr_infos = None

    async def _connect_sock(self, exceptions, addr_info, local_addr_infos=None):
        """Create, bind and connect one socket."""
        my_exceptions = []
        exceptions.append(my_exceptions)
        family, type_, proto, _, address = addr_info
        sock = None
        try:
            sock = socket.socket(family=family, type=type_, proto=proto)
            sock.setblocking(False)
            if local_addr_infos is not None:
                for lfamily, _, _, _, laddr in local_addr_infos:
                    # skip local addresses of different family
                    if lfamily != family:
                        continue
                    try:
                        sock.bind(laddr)
                        break
                    except OSError as exc:
                        msg = (
                            f'error while attempting to bind on '
                            f'address {laddr!r}: '
                            f'{exc.strerror.lower()}'
                        )
                        exc = OSError(exc.errno, msg)
                        my_exceptions.append(exc)
                else:  # all bind attempts failed
                    if my_exceptions:
                        raise my_exceptions.pop()
                    else:
                        raise OSError(f"no matching local address with {family=} found")
>           await self.sock_connect(sock, address)

/usr/lib/python3.12/asyncio/base_events.py:1007: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    async def sock_connect(self, sock, address):
        """Connect to a remote socket at address.
    
        This method is a coroutine.
        """
        base_events._check_ssl_socket(sock)
        if self._debug and sock.gettimeout() != 0:
            raise ValueError("the socket must be non-blocking")
    
        if sock.family == socket.AF_INET or (
                base_events._HAS_IPv6 and sock.family == socket.AF_INET6):
            resolved = await self._ensure_resolved(
                address, family=sock.family, type=sock.type, proto=sock.proto,
                loop=self,
            )
            _, _, _, _, address = resolved[0]
    
        fut = self.create_future()
        self._sock_connect(fut, sock, address)
        try:
>           return await fut
                   ^^^^^^^^^

/usr/lib/python3.12/asyncio/selector_events.py:651: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
fut = None, sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    def _sock_connect_cb(self, fut, sock, address):
        if fut.done():
            return
    
        try:
            err = sock.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
            if err != 0:
                # Jump to any except clause below.
>               raise OSError(err, f'Connect call failed {address}')
E               ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)

/usr/lib/python3.12/asyncio/selector_events.py:691: ConnectionRefusedError
_____________________ ERROR at setup of test_read_user_me ______________________

request = <SubRequest 'engine' for <Coroutine test_create_user>>, kwargs = {}
func = <function engine at 0x7fe1b3bc2ca0>
event_loop_fixture_id = '_session_event_loop'
setup = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup at 0x7fe1b1615940>
finalizer = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.finalizer at 0x7fe1b16158a0>

    @functools.wraps(fixture)
    def _asyncgen_fixture_wrapper(request: FixtureRequest, **kwargs: Any):
        func = _perhaps_rebind_fixture_func(fixture, request.instance)
        event_loop_fixture_id = _get_event_loop_fixture_id_for_async_fixture(
            request, func
        )
        event_loop = request.getfixturevalue(event_loop_fixture_id)
        kwargs.pop(event_loop_fixture_id, None)
        gen_obj = func(**_add_kwargs(func, kwargs, event_loop, request))
    
        async def setup():
            res = await gen_obj.__anext__()  # type: ignore[union-attr]
            return res
    
        def finalizer() -> None:
            """Yield again, to finalize."""
    
            async def async_finalizer() -> None:
                try:
                    await gen_obj.__anext__()  # type: ignore[union-attr]
                except StopAsyncIteration:
                    pass
                else:
                    msg = "Async generator fixture didn't stop."
                    msg += "Yield only once."
                    raise ValueError(msg)
    
            event_loop.run_until_complete(async_finalizer())
    
>       result = event_loop.run_until_complete(setup())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:343: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup() done, defined at /home/barbidou/.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:324> exception=ConnectionRefusedError(111, "Connect call failed ('127.0.0.1', 5432)")>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def setup():
>       res = await gen_obj.__anext__()  # type: ignore[union-attr]
              ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @pytest.fixture(scope="session")
    async def engine() -> AsyncGenerator:
        """Create a SQLAlchemy engine for testing."""
        engine = create_async_engine(TEST_DATABASE_URL, echo=False)
    
        # Create tables
>       async with engine.begin() as conn:

tests/conftest.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._AsyncGeneratorContextManager object at 0x7fe1b15d5820>

    async def __aenter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
>           return await anext(self.gen)
                   ^^^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/contextlib.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncEngine object at 0x7fe1b1724c10>

    @contextlib.asynccontextmanager
    async def begin(self) -> AsyncIterator[AsyncConnection]:
        """Return a context manager which when entered will deliver an
        :class:`_asyncio.AsyncConnection` with an
        :class:`_asyncio.AsyncTransaction` established.
    
        E.g.::
    
            async with async_engine.begin() as conn:
                await conn.execute(
                    text("insert into table (x, y, z) values (1, 2, 3)")
                )
                await conn.execute(text("my_special_procedure(5)"))
    
        """
        conn = self.connect()
    
>       async with conn:

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:1068: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/base.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
>               result = context.throw(*sys.exc_info())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7fe1b15d57c0>
engine = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()
                                         ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()
               ^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:447: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()
                  ^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:711: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b28fadd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()
                       ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)
               ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:388: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:673: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:899: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b170ffd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:895: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/create.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7fe1b15d5be0>
cargs = ()
cparams = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}

    def connect(self, *cargs: Any, **cparams: Any) -> DBAPIConnection:
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:629: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x7fe1b2519df0>
arg = ()
kw = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x7fe1b2baac00>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:955: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object connect at 0x7fe1b24365c0>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
>               value = await result
                        ^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=None,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None,
                      krbsrvname=None,
                      gsslib=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote_plus`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :param str krbsrvname:
            Kerberos service name to use when authenticating with GSSAPI. This
            must match the server configuration. Defaults to 'postgres'.
    
        :param str gsslib:
            GSS library to use for GSSAPI/SSPI authentication. Can be 'gssapi'
            or 'sspi'. Defaults to 'sspi' on Windows and 'gssapi' otherwise.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.run(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. versionchanged:: 0.30.0
           Added the *krbsrvname* and *gsslib* parameters.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs,
                krbsrvname=krbsrvname,
                gsslib=gsslib,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connection.py:2421: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
                conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )
                candidates.append(conn)
                if await _can_use_connection(conn, target_attr):
                    chosen_connection = conn
                    break
            except OSError as ex:
                last_error = ex
        else:
            if target_attr == SessionAttribute.prefer_standby and candidates:
                chosen_connection = random.choice(candidates)
    
        await asyncio.gather(
            *(c.close() for c in candidates if c is not chosen_connection),
            return_exceptions=True
        )
    
        if chosen_connection:
            return chosen_connection
    
>       raise last_error or exceptions.TargetServerAttributeNotMatched(
            'None of the hosts match the target attribute requirement '
            '{!r}'.format(target_attr)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1075: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1049: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:886: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
retry = True, addr = ('localhost', 5432)
loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.ssl_negotiation is SSLNegotiation.direct:
            # if ssl and ssl_negotiation is `direct`, skip STARTTLS and perform
            # direct SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
>       tr, pr = await connector
                 ^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:931: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

protocol_factory = <function __connect_addr.<locals>.<lambda> at 0x7fe1b1616840>
host = 'localhost', port = 5432

    async def _create_ssl_connection(protocol_factory, host, port, *,
                                     loop, ssl_context, ssl_is_advisory=False):
    
>       tr, pr = await loop.create_connection(
            lambda: TLSUpgradeProto(loop, host, port,
                                    ssl_context, ssl_is_advisory),
            host, port)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
                        sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)
                        break
                    except OSError:
                        continue
            else:  # using happy eyeballs
                sock, _, _ = await staggered.staggered_race(
                    (functools.partial(self._connect_sock,
                                       exceptions, addrinfo, laddr_infos)
                     for addrinfo in infos),
                    happy_eyeballs_delay, loop=self)
    
            if sock is None:
                exceptions = [exc for sub in exceptions for exc in sub]
                try:
                    if all_errors:
                        raise ExceptionGroup("create_connection failed", exceptions)
                    if len(exceptions) == 1:
>                       raise exceptions[0]

/usr/lib/python3.12/asyncio/base_events.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
>                       sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)

/usr/lib/python3.12/asyncio/base_events.py:1104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
exceptions = None
addr_info = (<AddressFamily.AF_INET: 2>, <SocketKind.SOCK_STREAM: 1>, 6, '', ('127.0.0.1', 5432))
local_addr_infos = None

    async def _connect_sock(self, exceptions, addr_info, local_addr_infos=None):
        """Create, bind and connect one socket."""
        my_exceptions = []
        exceptions.append(my_exceptions)
        family, type_, proto, _, address = addr_info
        sock = None
        try:
            sock = socket.socket(family=family, type=type_, proto=proto)
            sock.setblocking(False)
            if local_addr_infos is not None:
                for lfamily, _, _, _, laddr in local_addr_infos:
                    # skip local addresses of different family
                    if lfamily != family:
                        continue
                    try:
                        sock.bind(laddr)
                        break
                    except OSError as exc:
                        msg = (
                            f'error while attempting to bind on '
                            f'address {laddr!r}: '
                            f'{exc.strerror.lower()}'
                        )
                        exc = OSError(exc.errno, msg)
                        my_exceptions.append(exc)
                else:  # all bind attempts failed
                    if my_exceptions:
                        raise my_exceptions.pop()
                    else:
                        raise OSError(f"no matching local address with {family=} found")
>           await self.sock_connect(sock, address)

/usr/lib/python3.12/asyncio/base_events.py:1007: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    async def sock_connect(self, sock, address):
        """Connect to a remote socket at address.
    
        This method is a coroutine.
        """
        base_events._check_ssl_socket(sock)
        if self._debug and sock.gettimeout() != 0:
            raise ValueError("the socket must be non-blocking")
    
        if sock.family == socket.AF_INET or (
                base_events._HAS_IPv6 and sock.family == socket.AF_INET6):
            resolved = await self._ensure_resolved(
                address, family=sock.family, type=sock.type, proto=sock.proto,
                loop=self,
            )
            _, _, _, _, address = resolved[0]
    
        fut = self.create_future()
        self._sock_connect(fut, sock, address)
        try:
>           return await fut
                   ^^^^^^^^^

/usr/lib/python3.12/asyncio/selector_events.py:651: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
fut = None, sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    def _sock_connect_cb(self, fut, sock, address):
        if fut.done():
            return
    
        try:
            err = sock.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
            if err != 0:
                # Jump to any except clause below.
>               raise OSError(err, f'Connect call failed {address}')
E               ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)

/usr/lib/python3.12/asyncio/selector_events.py:691: ConnectionRefusedError
____________________ ERROR at setup of test_update_user_me _____________________

request = <SubRequest 'engine' for <Coroutine test_create_user>>, kwargs = {}
func = <function engine at 0x7fe1b3bc2ca0>
event_loop_fixture_id = '_session_event_loop'
setup = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup at 0x7fe1b1615940>
finalizer = <function _wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.finalizer at 0x7fe1b16158a0>

    @functools.wraps(fixture)
    def _asyncgen_fixture_wrapper(request: FixtureRequest, **kwargs: Any):
        func = _perhaps_rebind_fixture_func(fixture, request.instance)
        event_loop_fixture_id = _get_event_loop_fixture_id_for_async_fixture(
            request, func
        )
        event_loop = request.getfixturevalue(event_loop_fixture_id)
        kwargs.pop(event_loop_fixture_id, None)
        gen_obj = func(**_add_kwargs(func, kwargs, event_loop, request))
    
        async def setup():
            res = await gen_obj.__anext__()  # type: ignore[union-attr]
            return res
    
        def finalizer() -> None:
            """Yield again, to finalize."""
    
            async def async_finalizer() -> None:
                try:
                    await gen_obj.__anext__()  # type: ignore[union-attr]
                except StopAsyncIteration:
                    pass
                else:
                    msg = "Async generator fixture didn't stop."
                    msg += "Yield only once."
                    raise ValueError(msg)
    
            event_loop.run_until_complete(async_finalizer())
    
>       result = event_loop.run_until_complete(setup())
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:343: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
future = <Task finished name='Task-1' coro=<_wrap_asyncgen_fixture.<locals>._asyncgen_fixture_wrapper.<locals>.setup() done, defined at /home/barbidou/.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:324> exception=ConnectionRefusedError(111, "Connect call failed ('127.0.0.1', 5432)")>

    def run_until_complete(self, future):
        """Run until the Future is done.
    
        If the argument is a coroutine, it is wrapped in a Task.
    
        WARNING: It would be disastrous to call run_until_complete()
        with the same coroutine twice -- it would wrap it in two
        different Tasks and that can't be good.
    
        Return the Future's result, or raise its exception.
        """
        self._check_closed()
        self._check_running()
    
        new_task = not futures.isfuture(future)
        future = tasks.ensure_future(future, loop=self)
        if new_task:
            # An exception is raised if the future didn't complete, so there
            # is no need to log the "destroy pending task" message
            future._log_destroy_pending = False
    
        future.add_done_callback(_run_until_complete_cb)
        try:
            self.run_forever()
        except:
            if new_task and future.done() and not future.cancelled():
                # The coroutine raised a BaseException. Consume the exception
                # to not log a warning, the caller doesn't have access to the
                # local task.
                future.exception()
            raise
        finally:
            future.remove_done_callback(_run_until_complete_cb)
        if not future.done():
            raise RuntimeError('Event loop stopped before Future completed.')
    
>       return future.result()
               ^^^^^^^^^^^^^^^

/usr/lib/python3.12/asyncio/base_events.py:687: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def setup():
>       res = await gen_obj.__anext__()  # type: ignore[union-attr]
              ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/pytest_asyncio/plugin.py:325: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    @pytest.fixture(scope="session")
    async def engine() -> AsyncGenerator:
        """Create a SQLAlchemy engine for testing."""
        engine = create_async_engine(TEST_DATABASE_URL, echo=False)
    
        # Create tables
>       async with engine.begin() as conn:

tests/conftest.py:28: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <contextlib._AsyncGeneratorContextManager object at 0x7fe1b15d5820>

    async def __aenter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
>           return await anext(self.gen)
                   ^^^^^^^^^^^^^^^^^^^^^

/usr/lib/python3.12/contextlib.py:210: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncEngine object at 0x7fe1b1724c10>

    @contextlib.asynccontextmanager
    async def begin(self) -> AsyncIterator[AsyncConnection]:
        """Return a context manager which when entered will deliver an
        :class:`_asyncio.AsyncConnection` with an
        :class:`_asyncio.AsyncTransaction` established.
    
        E.g.::
    
            async with async_engine.begin() as conn:
                await conn.execute(
                    text("insert into table (x, y, z) values (1, 2, 3)")
                )
                await conn.execute(text("my_special_procedure(5)"))
    
        """
        conn = self.connect()
    
>       async with conn:

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:1068: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>

    async def __aenter__(self) -> _T_co:
>       return await self.start(is_ctxmanager=True)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/base.py:121: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.ext.asyncio.engine.AsyncConnection object at 0x7fe1b16594f0>
is_ctxmanager = True

    async def start(
        self, is_ctxmanager: bool = False  # noqa: U100
    ) -> AsyncConnection:
        """Start this :class:`_asyncio.AsyncConnection` object's context
        outside of using a Python ``with:`` block.
    
        """
        if self.sync_connection:
            raise exc.InvalidRequestError("connection is already started")
        self.sync_connection = self._assign_proxied(
>           await greenlet_spawn(self.sync_engine.connect)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/ext/asyncio/engine.py:275: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
                value = await result
            except BaseException:
                # this allows an exception to be raised within
                # the moderated greenlet so that it can continue
                # its expected flow.
>               result = context.throw(*sys.exc_info())
                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:201: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def connect(self) -> Connection:
        """Return a new :class:`_engine.Connection` object.
    
        The :class:`_engine.Connection` acts as a Python context manager, so
        the typical use of this method looks like::
    
            with engine.connect() as connection:
                connection.execute(text("insert into table values ('foo')"))
                connection.commit()
    
        Where above, after the block is completed, the connection is "closed"
        and its underlying DBAPI resources are returned to the connection pool.
        This also has the effect of rolling back any transaction that
        was explicitly begun or was begun via autobegin, and will
        emit the :meth:`_events.ConnectionEvents.rollback` event if one was
        started and is still in progress.
    
        .. seealso::
    
            :meth:`_engine.Engine.begin`
    
        """
    
>       return self._connection_cls(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3277: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.engine.base.Connection object at 0x7fe1b15d57c0>
engine = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)
connection = None, _has_events = None, _allow_revalidate = True
_allow_autobegin = True

    def __init__(
        self,
        engine: Engine,
        connection: Optional[PoolProxiedConnection] = None,
        _has_events: Optional[bool] = None,
        _allow_revalidate: bool = True,
        _allow_autobegin: bool = True,
    ):
        """Construct a new Connection."""
        self.engine = engine
        self.dialect = dialect = engine.dialect
    
        if connection is None:
            try:
>               self._dbapi_connection = engine.raw_connection()
                                         ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:143: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)

    def raw_connection(self) -> PoolProxiedConnection:
        """Return a "raw" DBAPI connection from the connection pool.
    
        The returned object is a proxied version of the DBAPI
        connection object used by the underlying driver in use.
        The object will have all the same behavior as the real DBAPI
        connection, except that its ``close()`` method will result in the
        connection being returned to the pool, rather than being closed
        for real.
    
        This method provides direct DBAPI connection access for
        special situations when the API provided by
        :class:`_engine.Connection`
        is not needed.   When a :class:`_engine.Connection` object is already
        present, the DBAPI connection is available using
        the :attr:`_engine.Connection.connection` accessor.
    
        .. seealso::
    
            :ref:`dbapi_connections`
    
        """
>       return self.pool.connect()
               ^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/base.py:3301: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def connect(self) -> PoolProxiedConnection:
        """Return a DBAPI connection from the pool.
    
        The connection is instrumented such that when its
        ``close()`` method is called, the connection will be returned to
        the pool.
    
        """
>       return _ConnectionFairy._checkout(self)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:447: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionFairy'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
threadconns = None, fairy = None

    @classmethod
    def _checkout(
        cls,
        pool: Pool,
        threadconns: Optional[threading.local] = None,
        fairy: Optional[_ConnectionFairy] = None,
    ) -> _ConnectionFairy:
        if not fairy:
>           fairy = _ConnectionRecord.checkout(pool)
                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:1264: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

cls = <class 'sqlalchemy.pool.base._ConnectionRecord'>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    @classmethod
    def checkout(cls, pool: Pool) -> _ConnectionFairy:
        if TYPE_CHECKING:
            rec = cast(_ConnectionRecord, pool._do_get())
        else:
>           rec = pool._do_get()
                  ^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:711: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
                return self._create_connection()
            except:
>               with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:177: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b28fadd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _do_get(self) -> ConnectionPoolEntry:
        use_overflow = self._max_overflow > -1
    
        wait = use_overflow and self._overflow >= self._max_overflow
        try:
            return self._pool.get(wait, self._timeout)
        except sqla_queue.Empty:
            # don't do things inside of "except Empty", because when we say
            # we timed out or can't connect and raise, Python 3 tells
            # people the real error is queue.Empty which it isn't.
            pass
        if use_overflow and self._overflow >= self._max_overflow:
            if not wait:
                return self._do_get()
            else:
                raise exc.TimeoutError(
                    "QueuePool limit of size %d overflow %d reached, "
                    "connection timed out, timeout %0.2f"
                    % (self.size(), self.overflow(), self._timeout),
                    code="3o7r",
                )
    
        if self._inc_overflow():
            try:
>               return self._create_connection()
                       ^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/impl.py:175: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>

    def _create_connection(self) -> ConnectionPoolEntry:
        """Called by subclasses to create a new ConnectionRecord."""
    
>       return _ConnectionRecord(self)
               ^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:388: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>
pool = <sqlalchemy.pool.impl.AsyncAdaptedQueuePool object at 0x7fe1b15d5c70>
connect = True

    def __init__(self, pool: Pool, connect: bool = True):
        self.fresh = False
        self.fairy_ref = None
        self.starttime = 0
        self.dbapi_connection = None
    
        self.__pool = pool
        if connect:
>           self.__connect()

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:673: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
            self.dbapi_connection = connection = pool._invoke_creator(self)
            pool.logger.debug("Created new connection %r", connection)
            self.fresh = True
        except BaseException as e:
>           with util.safe_reraise():

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:899: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.util.langhelpers.safe_reraise object at 0x7fe1b170ffd0>
type_ = None, value = None, traceback = None

    def __exit__(
        self,
        type_: Optional[Type[BaseException]],
        value: Optional[BaseException],
        traceback: Optional[types.TracebackType],
    ) -> NoReturn:
        assert self._exc_info is not None
        # see #2703 for notes
        if type_ is None:
            exc_type, exc_value, exc_tb = self._exc_info
            assert exc_value is not None
            self._exc_info = None  # remove potential circular references
>           raise exc_value.with_traceback(exc_tb)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/langhelpers.py:224: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def __connect(self) -> None:
        pool = self.__pool
    
        # ensure any existing connection is removed, so that if
        # creator fails, this attribute stays None
        self.dbapi_connection = None
        try:
            self.starttime = time.time()
>           self.dbapi_connection = connection = pool._invoke_creator(self)
                                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/pool/base.py:895: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

connection_record = <sqlalchemy.pool.base._ConnectionRecord object at 0x7fe1b1641c10>

    def connect(
        connection_record: Optional[ConnectionPoolEntry] = None,
    ) -> DBAPIConnection:
        if dialect._has_events:
            for fn in dialect.dispatch.do_connect:
                connection = cast(
                    DBAPIConnection,
                    fn(dialect, connection_record, cargs, cparams),
                )
                if connection is not None:
                    return connection
    
>       return dialect.connect(*cargs, **cparams)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/create.py:661: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.PGDialect_asyncpg object at 0x7fe1b15d5be0>
cargs = ()
cparams = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}

    def connect(self, *cargs: Any, **cparams: Any) -> DBAPIConnection:
        # inherits the docstring from interfaces.Dialect.connect
>       return self.loaded_dbapi.connect(*cargs, **cparams)  # type: ignore[no-any-return]  # NOQA: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/engine/default.py:629: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <sqlalchemy.dialects.postgresql.asyncpg.AsyncAdapt_asyncpg_dbapi object at 0x7fe1b2519df0>
arg = ()
kw = {'database': 'shinkei', 'host': 'localhost', 'password': 'shinkei_pass_dev_only', 'port': 5432, ...}
async_fallback = False, creator_fn = <function connect at 0x7fe1b2baac00>
prepared_statement_cache_size = 100, prepared_statement_name_func = None

    def connect(self, *arg, **kw):
        async_fallback = kw.pop("async_fallback", False)
        creator_fn = kw.pop("async_creator_fn", self.asyncpg.connect)
        prepared_statement_cache_size = kw.pop(
            "prepared_statement_cache_size", 100
        )
        prepared_statement_name_func = kw.pop(
            "prepared_statement_name_func", None
        )
    
        if util.asbool(async_fallback):
            return AsyncAdaptFallback_asyncpg_connection(
                self,
                await_fallback(creator_fn(*arg, **kw)),
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )
        else:
            return AsyncAdapt_asyncpg_connection(
                self,
>               await_only(creator_fn(*arg, **kw)),
                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
                prepared_statement_cache_size=prepared_statement_cache_size,
                prepared_statement_name_func=prepared_statement_name_func,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/dialects/postgresql/asyncpg.py:955: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

awaitable = <coroutine object connect at 0x7fe1b24365c0>

    def await_only(awaitable: Awaitable[_T]) -> _T:
        """Awaits an async function in a sync method.
    
        The sync method must be inside a :func:`greenlet_spawn` context.
        :func:`await_only` calls cannot be nested.
    
        :param awaitable: The coroutine to call.
    
        """
        # this is called in the context greenlet while running fn
        current = getcurrent()
        if not getattr(current, "__sqlalchemy_greenlet_provider__", False):
            _safe_cancel_awaitable(awaitable)
    
            raise exc.MissingGreenlet(
                "greenlet_spawn has not been called; can't call await_only() "
                "here. Was IO attempted in an unexpected place?"
            )
    
        # returns the control to the driver greenlet passing it
        # a coroutine to run. Once the awaitable is done, the driver greenlet
        # switches back to this greenlet with the result of awaitable that is
        # then returned to the caller (or raised as error)
>       return current.parent.switch(awaitable)  # type: ignore[no-any-return,attr-defined] # noqa: E501
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:132: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

fn = <bound method Engine.connect of Engine(postgresql+asyncpg://shinkei_user:***@localhost:5432/shinkei)>
_require_await = False, args = (), kwargs = {}
context = <_AsyncIoGreenlet object at 0x7fe1b1664080 (otid=0x7fe1b42d8480) dead>
switch_occurred = True, result = <coroutine object connect at 0x7fe1b24365c0>

    async def greenlet_spawn(
        fn: Callable[..., _T],
        *args: Any,
        _require_await: bool = False,
        **kwargs: Any,
    ) -> _T:
        """Runs a sync function ``fn`` in a new greenlet.
    
        The sync function can then use :func:`await_only` to wait for async
        functions.
    
        :param fn: The sync callable to call.
        :param \\*args: Positional arguments to pass to the ``fn`` callable.
        :param \\*\\*kwargs: Keyword arguments to pass to the ``fn`` callable.
        """
    
        result: Any
        context = _AsyncIoGreenlet(fn, getcurrent())
        # runs the function synchronously in gl greenlet. If the execution
        # is interrupted by await_only, context is not dead and result is a
        # coroutine to wait. If the context is dead the function has
        # returned, and its result can be returned.
        switch_occurred = False
        result = context.switch(*args, **kwargs)
        while not context.dead:
            switch_occurred = True
            try:
                # wait for a coroutine from await_only and then return its
                # result back to it.
>               value = await result
                        ^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/sqlalchemy/util/_concurrency_py3k.py:196: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

dsn = None

    async def connect(dsn=None, *,
                      host=None, port=None,
                      user=None, password=None, passfile=None,
                      database=None,
                      loop=None,
                      timeout=60,
                      statement_cache_size=100,
                      max_cached_statement_lifetime=300,
                      max_cacheable_statement_size=1024 * 15,
                      command_timeout=None,
                      ssl=None,
                      direct_tls=None,
                      connection_class=Connection,
                      record_class=protocol.Record,
                      server_settings=None,
                      target_session_attrs=None,
                      krbsrvname=None,
                      gsslib=None):
        r"""A coroutine to establish a connection to a PostgreSQL server.
    
        The connection parameters may be specified either as a connection
        URI in *dsn*, or as specific keyword arguments, or both.
        If both *dsn* and keyword arguments are specified, the latter
        override the corresponding values parsed from the connection URI.
        The default values for the majority of arguments can be specified
        using `environment variables <postgres envvars_>`_.
    
        Returns a new :class:`~asyncpg.connection.Connection` object.
    
        :param dsn:
            Connection arguments specified using as a single string in the
            `libpq connection URI format`_:
            ``postgres://user:password@host:port/database?option=value``.
            The following options are recognized by asyncpg: ``host``,
            ``port``, ``user``, ``database`` (or ``dbname``), ``password``,
            ``passfile``, ``sslmode``, ``sslcert``, ``sslkey``, ``sslrootcert``,
            and ``sslcrl``.  Unlike libpq, asyncpg will treat unrecognized
            options as `server settings`_ to be used for the connection.
    
            .. note::
    
               The URI must be *valid*, which means that all components must
               be properly quoted with :py:func:`urllib.parse.quote_plus`, and
               any literal IPv6 addresses must be enclosed in square brackets.
               For example:
    
               .. code-block:: text
    
                  postgres://dbuser@[fe80::1ff:fe23:4567:890a%25eth0]/dbname
    
        :param host:
            Database host address as one of the following:
    
            - an IP address or a domain name;
            - an absolute path to the directory containing the database
              server Unix-domain socket (not supported on Windows);
            - a sequence of any of the above, in which case the addresses
              will be tried in order, and the first successful connection
              will be returned.
    
            If not specified, asyncpg will try the following, in order:
    
            - host address(es) parsed from the *dsn* argument,
            - the value of the ``PGHOST`` environment variable,
            - on Unix, common directories used for PostgreSQL Unix-domain
              sockets: ``"/run/postgresql"``, ``"/var/run/postgresl"``,
              ``"/var/pgsql_socket"``, ``"/private/tmp"``, and ``"/tmp"``,
            - ``"localhost"``.
    
        :param port:
            Port number to connect to at the server host
            (or Unix-domain socket file extension).  If multiple host
            addresses were specified, this parameter may specify a
            sequence of port numbers of the same length as the host sequence,
            or it may specify a single port number to be used for all host
            addresses.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGPORT`` environment variable, or ``5432`` if
            neither is specified.
    
        :param user:
            The name of the database role used for authentication.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGUSER`` environment variable, or the
            operating system name of the user running the application.
    
        :param database:
            The name of the database to connect to.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGDATABASE`` environment variable, or the
            computed value of the *user* argument.
    
        :param password:
            Password to be used for authentication, if the server requires
            one.  If not specified, the value parsed from the *dsn* argument
            is used, or the value of the ``PGPASSWORD`` environment variable.
            Note that the use of the environment variable is discouraged as
            other users and applications may be able to read it without needing
            specific privileges.  It is recommended to use *passfile* instead.
    
            Password may be either a string, or a callable that returns a string.
            If a callable is provided, it will be called each time a new connection
            is established.
    
        :param passfile:
            The name of the file used to store passwords
            (defaults to ``~/.pgpass``, or ``%APPDATA%\postgresql\pgpass.conf``
            on Windows).
    
        :param loop:
            An asyncio event loop instance.  If ``None``, the default
            event loop will be used.
    
        :param float timeout:
            Connection timeout in seconds.
    
        :param int statement_cache_size:
            The size of prepared statement LRU cache.  Pass ``0`` to
            disable the cache.
    
        :param int max_cached_statement_lifetime:
            The maximum time in seconds a prepared statement will stay
            in the cache.  Pass ``0`` to allow statements be cached
            indefinitely.
    
        :param int max_cacheable_statement_size:
            The maximum size of a statement that can be cached (15KiB by
            default).  Pass ``0`` to allow all statements to be cached
            regardless of their size.
    
        :param float command_timeout:
            The default timeout for operations on this connection
            (the default is ``None``: no timeout).
    
        :param ssl:
            Pass ``True`` or an `ssl.SSLContext <SSLContext_>`_ instance to
            require an SSL connection.  If ``True``, a default SSL context
            returned by `ssl.create_default_context() <create_default_context_>`_
            will be used.  The value can also be one of the following strings:
    
            - ``'disable'`` - SSL is disabled (equivalent to ``False``)
            - ``'prefer'`` - try SSL first, fallback to non-SSL connection
              if SSL connection fails
            - ``'allow'`` - try without SSL first, then retry with SSL if the first
              attempt fails.
            - ``'require'`` - only try an SSL connection.  Certificate
              verification errors are ignored
            - ``'verify-ca'`` - only try an SSL connection, and verify
              that the server certificate is issued by a trusted certificate
              authority (CA)
            - ``'verify-full'`` - only try an SSL connection, verify
              that the server certificate is issued by a trusted CA and
              that the requested server host name matches that in the
              certificate.
    
            The default is ``'prefer'``: try an SSL connection and fallback to
            non-SSL connection if that fails.
    
            .. note::
    
               *ssl* is ignored for Unix domain socket communication.
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=verify-full&sslcert=..&sslkey=..&sslrootcert=..``:
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     # Load CA bundle for server certificate verification,
                ...     # equivalent to sslrootcert= in DSN.
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH,
                ...         cafile="path/to/ca_bundle.pem")
                ...     # If True, equivalent to sslmode=verify-full, if False:
                ...     # sslmode=verify-ca.
                ...     sslctx.check_hostname = True
                ...     # Load client certificate and private key for client
                ...     # authentication, equivalent to sslcert= and sslkey= in
                ...     # DSN.
                ...     sslctx.load_cert_chain(
                ...         "path/to/client.cert",
                ...         keyfile="path/to/client.key",
                ...     )
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
            Example of programmatic SSL context configuration that is equivalent
            to ``sslmode=require`` (no server certificate or host verification):
    
            .. code-block:: pycon
    
                >>> import asyncpg
                >>> import asyncio
                >>> import ssl
                >>> async def main():
                ...     sslctx = ssl.create_default_context(
                ...         ssl.Purpose.SERVER_AUTH)
                ...     sslctx.check_hostname = False
                ...     sslctx.verify_mode = ssl.CERT_NONE
                ...     con = await asyncpg.connect(user='postgres', ssl=sslctx)
                ...     await con.close()
                >>> asyncio.run(main())
    
        :param bool direct_tls:
            Pass ``True`` to skip PostgreSQL STARTTLS mode and perform a direct
            SSL connection. Must be used alongside ``ssl`` param.
    
        :param dict server_settings:
            An optional dict of server runtime parameters.  Refer to
            PostgreSQL documentation for
            a `list of supported options <server settings_>`_.
    
        :param type connection_class:
            Class of the returned connection object.  Must be a subclass of
            :class:`~asyncpg.connection.Connection`.
    
        :param type record_class:
            If specified, the class to use for records returned by queries on
            this connection object.  Must be a subclass of
            :class:`~asyncpg.Record`.
    
        :param SessionAttribute target_session_attrs:
            If specified, check that the host has the correct attribute.
            Can be one of:
    
            - ``"any"`` - the first successfully connected host
            - ``"primary"`` - the host must NOT be in hot standby mode
            - ``"standby"`` - the host must be in hot standby mode
            - ``"read-write"`` - the host must allow writes
            - ``"read-only"`` - the host most NOT allow writes
            - ``"prefer-standby"`` - first try to find a standby host, but if
              none of the listed hosts is a standby server,
              return any of them.
    
            If not specified, the value parsed from the *dsn* argument is used,
            or the value of the ``PGTARGETSESSIONATTRS`` environment variable,
            or ``"any"`` if neither is specified.
    
        :param str krbsrvname:
            Kerberos service name to use when authenticating with GSSAPI. This
            must match the server configuration. Defaults to 'postgres'.
    
        :param str gsslib:
            GSS library to use for GSSAPI/SSPI authentication. Can be 'gssapi'
            or 'sspi'. Defaults to 'sspi' on Windows and 'gssapi' otherwise.
    
        :return: A :class:`~asyncpg.connection.Connection` instance.
    
        Example:
    
        .. code-block:: pycon
    
            >>> import asyncpg
            >>> import asyncio
            >>> async def run():
            ...     con = await asyncpg.connect(user='postgres')
            ...     types = await con.fetch('SELECT * FROM pg_type')
            ...     print(types)
            ...
            >>> asyncio.run(run())
            [<Record typname='bool' typnamespace=11 ...
    
        .. versionadded:: 0.10.0
           Added ``max_cached_statement_use_count`` parameter.
    
        .. versionchanged:: 0.11.0
           Removed ability to pass arbitrary keyword arguments to set
           server settings.  Added a dedicated parameter ``server_settings``
           for that.
    
        .. versionadded:: 0.11.0
           Added ``connection_class`` parameter.
    
        .. versionadded:: 0.16.0
           Added ``passfile`` parameter
           (and support for password files in general).
    
        .. versionadded:: 0.18.0
           Added ability to specify multiple hosts in the *dsn*
           and *host* arguments.
    
        .. versionchanged:: 0.21.0
           The *password* argument now accepts a callable or an async function.
    
        .. versionchanged:: 0.22.0
           Added the *record_class* parameter.
    
        .. versionchanged:: 0.22.0
           The *ssl* argument now defaults to ``'prefer'``.
    
        .. versionchanged:: 0.24.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           are supported in the *dsn* argument.
    
        .. versionchanged:: 0.25.0
           The ``sslpassword``, ``ssl_min_protocol_version``,
           and ``ssl_max_protocol_version`` options are supported in the *dsn*
           argument.
    
        .. versionchanged:: 0.25.0
           Default system root CA certificates won't be loaded when specifying a
           particular sslmode, following the same behavior in libpq.
    
        .. versionchanged:: 0.25.0
           The ``sslcert``, ``sslkey``, ``sslrootcert``, and ``sslcrl`` options
           in the *dsn* argument now have consistent default values of files under
           ``~/.postgresql/`` as libpq.
    
        .. versionchanged:: 0.26.0
           Added the *direct_tls* parameter.
    
        .. versionchanged:: 0.28.0
           Added the *target_session_attrs* parameter.
    
        .. versionchanged:: 0.30.0
           Added the *krbsrvname* and *gsslib* parameters.
    
        .. _SSLContext: https://docs.python.org/3/library/ssl.html#ssl.SSLContext
        .. _create_default_context:
            https://docs.python.org/3/library/ssl.html#ssl.create_default_context
        .. _server settings:
            https://www.postgresql.org/docs/current/static/runtime-config.html
        .. _postgres envvars:
            https://www.postgresql.org/docs/current/static/libpq-envars.html
        .. _libpq connection URI format:
            https://www.postgresql.org/docs/current/static/
            libpq-connect.html#LIBPQ-CONNSTRING
        """
        if not issubclass(connection_class, Connection):
            raise exceptions.InterfaceError(
                'connection_class is expected to be a subclass of '
                'asyncpg.Connection, got {!r}'.format(connection_class))
    
        if record_class is not protocol.Record:
            _check_record_class(record_class)
    
        if loop is None:
            loop = asyncio.get_event_loop()
    
        async with compat.timeout(timeout):
>           return await connect_utils._connect(
                loop=loop,
                connection_class=connection_class,
                record_class=record_class,
                dsn=dsn,
                host=host,
                port=port,
                user=user,
                password=password,
                passfile=passfile,
                ssl=ssl,
                direct_tls=direct_tls,
                database=database,
                server_settings=server_settings,
                command_timeout=command_timeout,
                statement_cache_size=statement_cache_size,
                max_cached_statement_lifetime=max_cached_statement_lifetime,
                max_cacheable_statement_size=max_cacheable_statement_size,
                target_session_attrs=target_session_attrs,
                krbsrvname=krbsrvname,
                gsslib=gsslib,
            )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connection.py:2421: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
                conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )
                candidates.append(conn)
                if await _can_use_connection(conn, target_attr):
                    chosen_connection = conn
                    break
            except OSError as ex:
                last_error = ex
        else:
            if target_attr == SessionAttribute.prefer_standby and candidates:
                chosen_connection = random.choice(candidates)
    
        await asyncio.gather(
            *(c.close() for c in candidates if c is not chosen_connection),
            return_exceptions=True
        )
    
        if chosen_connection:
            return chosen_connection
    
>       raise last_error or exceptions.TargetServerAttributeNotMatched(
            'None of the hosts match the target attribute requirement '
            '{!r}'.format(target_attr)
        )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1075: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
kwargs = {'command_timeout': None, 'database': 'shinkei', 'direct_tls': None, 'dsn': None, ...}
addrs = [('localhost', 5432)]
params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
target_attr = <SessionAttribute.any: 'any'>

    async def _connect(*, loop, connection_class, record_class, **kwargs):
        if loop is None:
            loop = asyncio.get_event_loop()
    
        addrs, params, config = _parse_connect_arguments(**kwargs)
        target_attr = params.target_session_attrs
    
        candidates = []
        chosen_connection = None
        last_error = None
        for addr in addrs:
            try:
>               conn = await _connect_addr(
                    addr=addr,
                    loop=loop,
                    params=params,
                    config=config,
                    connection_class=connection_class,
                    record_class=record_class,
                )

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:1049: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

    async def _connect_addr(
        *,
        addr,
        loop,
        params,
        config,
        connection_class,
        record_class
    ):
        assert loop is not None
    
        params_input = params
        if callable(params.password):
            password = params.password()
            if inspect.isawaitable(password):
                password = await password
    
            params = params._replace(password=password)
        args = (addr, loop, config, connection_class, record_class, params_input)
    
        # prepare the params (which attempt has ssl) for the 2 attempts
        if params.sslmode == SSLMode.allow:
            params_retry = params
            params = params._replace(ssl=None)
        elif params.sslmode == SSLMode.prefer:
            params_retry = params._replace(ssl=None)
        else:
            # skip retry if we don't have to
            return await __connect_addr(params, False, *args)
    
        # first attempt
        try:
>           return await __connect_addr(params, True, *args)
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:886: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

params = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')
retry = True, addr = ('localhost', 5432)
loop = <_UnixSelectorEventLoop running=False closed=False debug=False>
config = ConnectionConfiguration(command_timeout=None, statement_cache_size=100, max_cached_statement_lifetime=300, max_cacheable_statement_size=15360)
connection_class = <class 'asyncpg.connection.Connection'>
record_class = <class 'asyncpg.Record'>
params_input = ConnectionParameters(user='shinkei_user', password='shinkei_pass_dev_only', database='shinkei', ssl=<ssl.SSLContext object at 0x7fe1b164d1d0>, sslmode=<SSLMode.prefer: 2>, ssl_negotiation=<SSLNegotiation.postgres: 'postgres'>, server_settings=None, target_session_attrs=<SessionAttribute.any: 'any'>, krbsrvname=None, gsslib='gssapi')

    async def __connect_addr(
        params,
        retry,
        addr,
        loop,
        config,
        connection_class,
        record_class,
        params_input,
    ):
        connected = _create_future(loop)
    
        proto_factory = lambda: protocol.Protocol(
            addr, connected, params, record_class, loop)
    
        if isinstance(addr, str):
            # UNIX socket
            connector = loop.create_unix_connection(proto_factory, addr)
    
        elif params.ssl and params.ssl_negotiation is SSLNegotiation.direct:
            # if ssl and ssl_negotiation is `direct`, skip STARTTLS and perform
            # direct SSL connection
            connector = loop.create_connection(
                proto_factory, *addr, ssl=params.ssl
            )
    
        elif params.ssl:
            connector = _create_ssl_connection(
                proto_factory, *addr, loop=loop, ssl_context=params.ssl,
                ssl_is_advisory=params.sslmode == SSLMode.prefer)
        else:
            connector = loop.create_connection(proto_factory, *addr)
    
>       tr, pr = await connector
                 ^^^^^^^^^^^^^^^

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:931: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

protocol_factory = <function __connect_addr.<locals>.<lambda> at 0x7fe1b1616840>
host = 'localhost', port = 5432

    async def _create_ssl_connection(protocol_factory, host, port, *,
                                     loop, ssl_context, ssl_is_advisory=False):
    
>       tr, pr = await loop.create_connection(
            lambda: TLSUpgradeProto(loop, host, port,
                                    ssl_context, ssl_is_advisory),
            host, port)

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/asyncpg/connect_utils.py:802: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
                        sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)
                        break
                    except OSError:
                        continue
            else:  # using happy eyeballs
                sock, _, _ = await staggered.staggered_race(
                    (functools.partial(self._connect_sock,
                                       exceptions, addrinfo, laddr_infos)
                     for addrinfo in infos),
                    happy_eyeballs_delay, loop=self)
    
            if sock is None:
                exceptions = [exc for sub in exceptions for exc in sub]
                try:
                    if all_errors:
                        raise ExceptionGroup("create_connection failed", exceptions)
                    if len(exceptions) == 1:
>                       raise exceptions[0]

/usr/lib/python3.12/asyncio/base_events.py:1122: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
protocol_factory = <function _create_ssl_connection.<locals>.<lambda> at 0x7fe1b16168e0>
host = 'localhost', port = 5432

    async def create_connection(
            self, protocol_factory, host=None, port=None,
            *, ssl=None, family=0,
            proto=0, flags=0, sock=None,
            local_addr=None, server_hostname=None,
            ssl_handshake_timeout=None,
            ssl_shutdown_timeout=None,
            happy_eyeballs_delay=None, interleave=None,
            all_errors=False):
        """Connect to a TCP server.
    
        Create a streaming transport connection to a given internet host and
        port: socket family AF_INET or socket.AF_INET6 depending on host (or
        family if specified), socket type SOCK_STREAM. protocol_factory must be
        a callable returning a protocol instance.
    
        This method is a coroutine which will try to establish the connection
        in the background.  When successful, the coroutine returns a
        (transport, protocol) pair.
        """
        if server_hostname is not None and not ssl:
            raise ValueError('server_hostname is only meaningful with ssl')
    
        if server_hostname is None and ssl:
            # Use host as default for server_hostname.  It is an error
            # if host is empty or not set, e.g. when an
            # already-connected socket was passed or when only a port
            # is given.  To avoid this error, you can pass
            # server_hostname='' -- this will bypass the hostname
            # check.  (This also means that if host is a numeric
            # IP/IPv6 address, we will attempt to verify that exact
            # address; this will probably fail, but it is possible to
            # create a certificate for a specific IP address, so we
            # don't judge it here.)
            if not host:
                raise ValueError('You must set server_hostname '
                                 'when using ssl without a host')
            server_hostname = host
    
        if ssl_handshake_timeout is not None and not ssl:
            raise ValueError(
                'ssl_handshake_timeout is only meaningful with ssl')
    
        if ssl_shutdown_timeout is not None and not ssl:
            raise ValueError(
                'ssl_shutdown_timeout is only meaningful with ssl')
    
        if sock is not None:
            _check_ssl_socket(sock)
    
        if happy_eyeballs_delay is not None and interleave is None:
            # If using happy eyeballs, default to interleave addresses by family
            interleave = 1
    
        if host is not None or port is not None:
            if sock is not None:
                raise ValueError(
                    'host/port and sock can not be specified at the same time')
    
            infos = await self._ensure_resolved(
                (host, port), family=family,
                type=socket.SOCK_STREAM, proto=proto, flags=flags, loop=self)
            if not infos:
                raise OSError('getaddrinfo() returned empty list')
    
            if local_addr is not None:
                laddr_infos = await self._ensure_resolved(
                    local_addr, family=family,
                    type=socket.SOCK_STREAM, proto=proto,
                    flags=flags, loop=self)
                if not laddr_infos:
                    raise OSError('getaddrinfo() returned empty list')
            else:
                laddr_infos = None
    
            if interleave:
                infos = _interleave_addrinfos(infos, interleave)
    
            exceptions = []
            if happy_eyeballs_delay is None:
                # not using happy eyeballs
                for addrinfo in infos:
                    try:
>                       sock = await self._connect_sock(
                            exceptions, addrinfo, laddr_infos)

/usr/lib/python3.12/asyncio/base_events.py:1104: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
exceptions = None
addr_info = (<AddressFamily.AF_INET: 2>, <SocketKind.SOCK_STREAM: 1>, 6, '', ('127.0.0.1', 5432))
local_addr_infos = None

    async def _connect_sock(self, exceptions, addr_info, local_addr_infos=None):
        """Create, bind and connect one socket."""
        my_exceptions = []
        exceptions.append(my_exceptions)
        family, type_, proto, _, address = addr_info
        sock = None
        try:
            sock = socket.socket(family=family, type=type_, proto=proto)
            sock.setblocking(False)
            if local_addr_infos is not None:
                for lfamily, _, _, _, laddr in local_addr_infos:
                    # skip local addresses of different family
                    if lfamily != family:
                        continue
                    try:
                        sock.bind(laddr)
                        break
                    except OSError as exc:
                        msg = (
                            f'error while attempting to bind on '
                            f'address {laddr!r}: '
                            f'{exc.strerror.lower()}'
                        )
                        exc = OSError(exc.errno, msg)
                        my_exceptions.append(exc)
                else:  # all bind attempts failed
                    if my_exceptions:
                        raise my_exceptions.pop()
                    else:
                        raise OSError(f"no matching local address with {family=} found")
>           await self.sock_connect(sock, address)

/usr/lib/python3.12/asyncio/base_events.py:1007: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    async def sock_connect(self, sock, address):
        """Connect to a remote socket at address.
    
        This method is a coroutine.
        """
        base_events._check_ssl_socket(sock)
        if self._debug and sock.gettimeout() != 0:
            raise ValueError("the socket must be non-blocking")
    
        if sock.family == socket.AF_INET or (
                base_events._HAS_IPv6 and sock.family == socket.AF_INET6):
            resolved = await self._ensure_resolved(
                address, family=sock.family, type=sock.type, proto=sock.proto,
                loop=self,
            )
            _, _, _, _, address = resolved[0]
    
        fut = self.create_future()
        self._sock_connect(fut, sock, address)
        try:
>           return await fut
                   ^^^^^^^^^

/usr/lib/python3.12/asyncio/selector_events.py:651: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <_UnixSelectorEventLoop running=False closed=False debug=False>
fut = None, sock = <socket.socket [closed] fd=-1, family=2, type=1, proto=6>
address = ('127.0.0.1', 5432)

    def _sock_connect_cb(self, fut, sock, address):
        if fut.done():
            return
    
        try:
            err = sock.getsockopt(socket.SOL_SOCKET, socket.SO_ERROR)
            if err != 0:
                # Jump to any except clause below.
>               raise OSError(err, f'Connect call failed {address}')
E               ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)

/usr/lib/python3.12/asyncio/selector_events.py:691: ConnectionRefusedError
=============================== warnings summary ===============================
src/shinkei/main.py:43
  /home/barbidou/SHINKEI/backend/src/shinkei/main.py:43: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    @app.on_event("startup")

../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/fastapi/applications.py:4495
../../.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/fastapi/applications.py:4495
  /home/barbidou/.cache/pypoetry/virtualenvs/shinkei-backend-YIt7ig1g-py3.12/lib/python3.12/site-packages/fastapi/applications.py:4495: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    return self.router.on_event(event_type)

src/shinkei/main.py:48
  /home/barbidou/SHINKEI/backend/src/shinkei/main.py:48: DeprecationWarning: 
          on_event is deprecated, use lifespan event handlers instead.
  
          Read more about it in the
          [FastAPI docs for Lifespan Events](https://fastapi.tiangolo.com/advanced/events/).
          
    @app.on_event("shutdown")

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
================================ tests coverage ================================
_______________ coverage: platform linux, python 3.12.3-final-0 ________________

Name                                       Stmts   Miss  Cover
--------------------------------------------------------------
src/shinkei/__init__.py                        1      0   100%
src/shinkei/api/__init__.py                    0      0   100%
src/shinkei/api/v1/__init__.py                 0      0   100%
src/shinkei/api/v1/api.py                      4      0   100%
src/shinkei/api/v1/endpoints/__init__.py       0      0   100%
src/shinkei/api/v1/endpoints/users.py         30     14    53%
src/shinkei/auth/dependencies.py              37     22    41%
src/shinkei/config.py                         29      0   100%
src/shinkei/database/engine.py                27     14    48%
src/shinkei/logging_config.py                 12      1    92%
src/shinkei/main.py                           20      3    85%
src/shinkei/models/story.py                   26      1    96%
src/shinkei/models/story_beat.py              25      1    96%
src/shinkei/models/user.py                    17      1    94%
src/shinkei/models/world.py                   28      1    96%
src/shinkei/models/world_event.py             24      1    96%
src/shinkei/repositories/user.py              53     37    30%
src/shinkei/schemas/user.py                   27      0   100%
--------------------------------------------------------------
TOTAL                                        360     96    73%
Coverage HTML written to dir htmlcov
=========================== short test summary info ============================
ERROR tests/api/test_users.py::test_create_user - ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)
ERROR tests/api/test_users.py::test_read_user_me - ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)
ERROR tests/api/test_users.py::test_update_user_me - ConnectionRefusedError: [Errno 111] Connect call failed ('127.0.0.1', 5432)
======================== 4 warnings, 3 errors in 1.89s =========================
